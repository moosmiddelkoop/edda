---
title: "Assignment 1"
author: "Gijs Smeets, Daan Wijnhorst, Moos Middelkoop, group 35"
date: "February 2023"
output:
  html_document:
    df_print: paged
fontsize: 11pt
highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 1. Birthweights

LOADING IN DATA
```{r}
data = read.table('../data/birthweight.txt',header=TRUE)
x = data$birthweight
```


#### A
##### Check normality of the data. Assuming normality (irrespective of your conclusion about normality), construct a bounded 96%-CI for mu. Evaluate the sample size needed to provide that the length of the 96%-CI is at most 100. Compute a bootstrap 96%-CI for mu and compare it to the above CI.

To check for normality we use a Shapiro-Wilk test. The null-hypothesis for this test is that the data is normally distributed. While it is not possible to infer results from a failed rejection of the null hypothesis (Schmidt and Vorberg, 2006), the result of this test can tell us if there is no significant non-normality present.

```{r}
shapiro.test(x)
```

Additionally, we create a qqplot to plot the quantiles of our data against those of a normal distribution, to get a visual impression of the normality of the data.

```{r,echo=FALSE,figheight=1.5}
qqnorm(x); qqline(x)
```

The linearity of this plot and a `p=0.8895` gives us a strong impression that our data is normally distributed. Now we can go on to construct the 95% confidence interval (CI) for mu, assuming normality.

```{r}
mean = mean(x)
sd = sd(x)
n = length(x)

ci = c((mean - qnorm(0.98)*(sd/sqrt(n))), (mean + qnorm(0.98)*(sd/sqrt(n))))
```

This results in a confidence interval of [`r round(ci,3)`]

The margin of error is 50. Following theory, we have to show that (mathematical: show that `qnorm(0.98)*(sd/sqrt(n)) =< 50)`)
n must be larger or equal to `min_n`
```{r}
min_n = ((qnorm(0.98)^2)*(sd^2))/(50^2)
```
This results in `r round(min_n,3)`.

96% bootstrap ci
```{r}
B = 1000
Tstar = numeric(B);
for (i in 1:B){
  Xstar = sample(x,replace=TRUE)
  Tstar[i] = mean(Xstar)
}
Tstar20 = quantile(Tstar,0.020)[[1]]
Tstar980 = quantile(Tstar,0.975)[[1]]
bootstrapci = c(2*mean-Tstar980,2*mean-Tstar20)
```

comparison ci vs bootstrap ci
```{r}
lenci = ci[2]-ci[1]
lenbsci = bootstrapci[2]-bootstrapci[1]
lenbsci<lenci 
```

### B

```{r}
t.test(x,mu=2800,alt="g")
```
As p-value is ... , reject null hypothesis.
Explain CI in t test results

Proposed sign test: T = #(x>2800)
```{r}
nT = length(x[x>2800]); 
pttest = t.test(x,mu=2800,alt="g")[[3]]
psign = binom.test(nT,n,p=0.5)[[3]]
```

Compare -> should we simulate? or is one enough
```{r}
pttest<psign
```
Talk about diff of tests, which is better etc. (comparison of p-values)

### C
Compute powers -> look at this

### D
```{r}
q = length(x[x<2600])/n - 0.25
pr = length(x[x<2600])/n + q
```

```{r}
ci_p = c(0.25,pr)
```
Confidence interval is [`r round(ci_p,3)`]


Now compute confidence level, by (math): q = z_(a/2) * sd/sqrt(n), so z_(a/2) = q * sqrt(n) / sd
```{r}
z = q * (sqrt(n) / sd)
pnorm(z)
```

Is this correct? -> alpha. Look at this


### E


## Exercise 2

### A
```{r}
data = read.table('../data/cholesterol.txt',header=TRUE); data
before = data$Before
after = data$After8weeks
summary(data)
shapiro.test(before)
shapiro.test(after)
```
```{r,echo=FALSE}
reg = lm(after ~ before)
plot(before,after, pch=16, col="blue")
abline(reg)
```
summary(reg) adj R^2 = 0.98 explained, correlated positively, but less than 1 so cholesterol level gets less. 

But easier to see, if we remove before bias and only look at first differences:
```{r,echo=FALSE}
diff = after - before
reg2 = lm(diff ~ before)
plot(before,diff, pch=16, col="red")
abline(reg2)
summary(reg2)
```
Notice that decrease in cholesterol level is higher for people who have higher cholesterol level before the experiment

### B

### C

### D

### E


## Exercise 3

### A

### B

### C

### D

### E


## Exercise 4

### A

### B

### C

### D

### E

