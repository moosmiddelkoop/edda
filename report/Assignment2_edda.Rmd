---
title: "Assignment 2"
author: "Gijs Smeets, Daan Wijnhorst, Moos Middelkoop group 35"
date: "February 2023"
output:
  html_document:
    df_print: paged
fontsize: 11pt
highlight: tango
---

## Exercise 2

### A
```{r}
data = read.table('../data/cholesterol.txt',header=TRUE)
before = data$Before
after = data$After8weeks
summary(data)
shapiro.test(before)
shapiro.test(after)
```
As the p-value from the Shapiro-Wilk test is high (0.9675) we do not reject the null-hypothesis and we conclude the data to be normally distributed.

```{r,echo=FALSE, fig.margin = FALSE,fig.width=12,fig.height=6,fig.align="center"}
par(mfrow=c(1,2))
reg = lm(after ~ before)
plot(before,after, pch=16, col="blue")
abline(reg)
diff = after - before
reg2 = lm(diff ~ before)
plot(before,diff, pch=16, col="red")
abline(reg2)
summary(reg2)
```
summary(reg) adj R^2 = 0.98 explained, correlated positively, but less than 1 so cholesterol level gets less. 
But easier to see, if we remove before bias and only look at first differences (see the right red plot )
Notice that decrease in cholesterol level is higher for people who have higher cholesterol level before the experiment.

### B
#### Pearson Correlation test

We can indeed devise a permutation test as we can look for a difference between X Y within pairs in the data.
```{r, fig.margin = FALSE,fig.width=6,fig.height=4,fig.align="center"} 
meansamples = function(x,y) {mean(x-y)}
B=1000; Tstar = numeric(B)
for (i in 1:B){
  dietstar = t(apply(cbind(before,after),1,sample))
  Tstar[i] = meansamples(dietstar[,1],dietstar[,2])
}
myt = meansamples(before,after);
hist(Tstar)
```
```{r} 
pl = sum(Tstar<myt)/B
pr = sum(Tstar>myt)/B
p = 2*min(pl,pr)
p
```
From this permutation test we conclude that there is indeed a significant difference between the before and after 8 weeks data.

As we have seen the data to be normally distributed in A, we can conduct a Paired-Sampled T-test

```{r} 
#T-test
t.test(before, after, paired = TRUE)
```
As the p-value is below 0.05 we reject H0 and conclude the mean paired differences are not equal to zero.

Another relevant test is testing for correlation.

We use the Pearson correlation test if the data is normally distributed and otherwise the Spearman test. From the QQplot the data looks normal.

```{r, fig.margin = FALSE,fig.width=8,fig.height=4,fig.align="center"} 
#pearson corr. test
par(mfrow=c(1,2))
cor.test(before,after)
qqnorm(before,main="Q-Q Plot Before")
qqnorm(after,main="Q-Q Plot After")

#seems like normal, but if not: use spearman
cor.test(before,after,method="spearman")
```
Pearson's returns the correlation value of 0.9908885 and Spearman's  p-value = 9.753e-06 herefore we conclude there exists a strong correlation.
### C
```{r} 
# function that computes variance of uniformly distr. variable
unif_var = function(a,b){
  return ((1/12)*((b-a)^2))
}

# E(X) = (a+b)/2 = mean(after)
# So point estimate of b is 2*E(X)-3
theta_est = 2*mean(after)-3

#build 95%-CI for theta_est
n = length(after)
ci_theta = c(theta_est - qnorm(0.975)*(sqrt(unif_var(3,theta_est))/sqrt(n)), theta_est + qnorm(0.975)*(sqrt(unif_var(3,theta_est))/sqrt(n)))
ci_theta


```
### D

#bootstrap test
```{r} 
t = max(after); t

vP = rep(0,9)
vT = rep(0,9)
for (theta in 3:12){
  B = 1000; tstar=numeric(B)
  
  for (i in 1:B){
    xstar=runif(n,3,theta)
    tstar[i] = max(xstar)
  }
  
  pl = sum(tstar<t)/B; pr = sum(tstar>t)/B
  p = 2*min(pl,pr); p
  
  vT[theta-2] = theta
  vP[theta-2] = p
  
}
res = rbind(vT,vP); res

# kolmogorov-smirnov can not be applied, explain.... (totally diff test)

```
Kolmogorov-Smirnov test can not be applied as 

### E